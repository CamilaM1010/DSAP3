Administrative:

Team Name: The Tryhard Treeo
Team Members + Github user names: 
	Camila Menendez- @CamilaM1010
	Paola Bechalani- @paolabechalani
	Omar Travieso- @otravieso

Link to GitHub repo: https://github.com/CamilaM1010/DSAP3.git 
Link to Video demo: **have to make video


Extended and Refined Proposal: 

Problem: In this project, we aim to address the challenge of fragmented information about video games, including their ratings and sales, scattered across various platforms and websites. This scattered data makes it difficult for users, such as players, investors, or game developers, to find and compare information on games efficiently. Our goal is to create a comprehensive solution that consolidates this information, allowing users to easily identify the highest and lowest-rated games, as well as the most and least expensive ones. This platform will facilitate the decision-making process, making it easier to analyze the video game market without having to navigate multiple websites or sources.

Motivation: The motivation for this project stems from the team’s own experience and frustrations with the current state of video game information. With the abundance of gaming platforms and websites, it can be time-consuming and difficult to find a reliable source that provides all the necessary data for making informed decisions. Whether it's identifying the best-rated games or evaluating sales figures, users often struggle to find a single platform that offers these insights in an organized and user-friendly manner. By addressing this issue, our project seeks to improve how users access and interact with video game data, enabling better decision-making for consumers, investors, and companies altogether.

Features Implemented: The primary objective of this project was to create a platform that consolidates scattered video game data from various sources, allowing users to find relevant information efficiently. We will know our project is fully functional when the user can gather the data they want from our database without any failures. One of the key features implemented was the ability to sort and filter games based on specific criteria, such as name, year of release, sales for different countries, critic score, critic count, user score, and user count. At the beginning, the user is welcomed to the page and prompted to choose from what category they would like to see sorted. This is followed by asking if they would like to cap the amount of responses. For example, if a user inputs 10, the top 10 of the category they chose will be displayed. When sorting by names it will be alphabetical, but when sorting by the other numerical categories, the user will be able to choose whether they want oldest to newest, for years, or least to greatest or greatest to least for the other options. 
To meet the goal of analyzing 100,000 data points, the program uses over 7 of the categories and displays all 16 of its attributes. Users can search for games based on specific characteristics, such as the "top 10 sellers in Japan" or the "top 10 highest-rated Nintendo games." The sorting algorithms, Quicksort and Mergesort, are used to arrange the data in order of sales and ratings, with additional categories being incorporated into the sorting process as needed. This allows for comprehensive insights into the market, making it easier for players, investors, and game developers to make informed decisions.

Description of Data: To ensure the reliability of the platform, the dataset includes over 100,000 entries, covering a wide variety of video games. The dataset includes the following information about each video game: name, platform, release year, genre, publisher, sales by region, global sales, critic score, critic count, user score, user count, developer, and rating. There are 16,720 different video games listed which gives great variety and utility to this dataset. 

Tools/Languages/APIs/Libraries used: We utilized CLion as our primary IDE for its advanced debugging features and seamless integration with CMake. The project was implemented in C++ to take advantage of its efficiency and suitability for algorithmic development, as well as because it is the language we are all most comfortable with. 

Algorithms Implemented: For this project, we chose to implement Quicksort and Mergesort, two well-known and efficient sorting algorithms.

Additional Data Structures/Algorithms: For this project, we implemented a class of VideoGames which used nodes as a simple data structure to store the 16 attributes. Additionally, we used vectors to store the VideoGame nodes which gave us easier access to the information we needed through the program. Lastly, we used a csv file reader to parse through the large amount of data.

Distribution of Responsibility and Roles: The roles were distributed as follows: 
Camila: csv file reader, incorporating clock, string sorting, updating sort to work with main, GUI
Paola: original quicksort and mergesort, refactoring part 3a, final report 
Omar: VideoGame class, GUI

We were all equally responsible for brainstorming project ideas, writing our reflections on the report, commenting on the code and being supportive team members if anyone needed extra help.
Analysis 

Any changes the group made after the proposal? The rationale behind the changes:
The most significant change our group faced was revising the original proposal plan. Early on, we realized that the data we had collected was insufficient to reach 100,000 data points. This prompted us to find a new dataset, which led to a shift in our approach. Initially, we intended to compare tree traversal methods, such as Red-Black trees and AVL trees. Later, we considered implementing algorithms like Dijkstra’s, Prim’s, or Kruskal’s. However, we found that our data lacked the relevant weights required to establish meaningful node connections.
As a result, we pivoted to focus on sorting algorithms instead. By incorporating a timer, we could evaluate and compare the speed at which each algorithm sorted our data. We chose Quicksort and Mergesort, as they both provided sufficient grounds for comparison in terms of sorting efficiency and practical implementation.
These changes also led to refinements in how we approached the dataset and the algorithms, ensuring that we could meet the project’s goal of processing a large amount of data. Although we made many changes along the way, every adjustment was made to create the best possible project. In the end, these revisions allowed us to deliver a more robust and relevant solution, which significantly improved the outcome of the project.

Big O worst case time complexity analysis:
** n is the size of the vector
** assumes string length is negligible
** videoGame class and its functionality is all O(1) because it assigns values to variables

mergeSorter, mergeSorterWords: O(nlog(n)) is the time complexity of these functions in the worst case scenario. The algorithm divides the array of strings for mergeSorterWords and floats for mergeSorter into halves making it log(n) levels of recursion and processes every level to merge them which would be n comparisons per level. 
mergeSortHelper, mergeSorterHelperWords: O(nlog(n)) is the time complexity of the merge helper functions because it has the same logic as the main sorter functions. The recursive division occurs log(n) times, and merging at each step requires processing all n elements. The type of data used, floats and strings, doesn’t affect this logic.
merge, mergeWords: O(n) is the time complexity in worst-case because it has to traverse both sides therefore the whole list. Other loops traverse both sides, but at different times, so you add and it ends up simplifying to the entire vector.
quicksort, quicksortWords: O(n2) is the time complexity of this function in the worst-case scenario because the pivot consistently divides the list into highly unbalanced parts, such as when the pivot is the smallest or largest element. This results in n recursive calls, each processing a nearly full subarray.
quickSortPriv, quicksortPrivWords:  O(n2) is the worst case time complexity because it recursively calls partitions to split and sort both halves of the list. If the partition is highly unbalanced it will lead to n2. Additionally, because the vector is split, the list is traversed twice in one loop.
partition, partitionWords: O(n) is the worst case time complexity because it processes all the elements to arrange them around the pivot. The pointers “up” and “down” end up at opposite ends meaning the whole list is traversed. 
swap, swapWords: O(1) is the worst case time complexity because these functions swap the two strings, or floats, with their associated videoGame object resulting in constant time.


Reflection: 

As a group, how was the overall experience for the project?
At the start of the project, we were uncertain about the direction, but as we progressed, communication improved, and we aligned on our objectives. Regular check-ins kept us on track, and we broke down tasks clearly, ensuring everyone knew their responsibilities.
What worked well was the transparency within the team. Everyone understood their strengths and areas for growth, enabling us to support each other and tackle challenges effectively. Although there were times of stress, we talked it out and supported each other which allowed for us to finish the project. We encountered challenges but also saw this as a learning opportunity in both teamwork and programming. 

Did you have any challenges? If so, describe.
We faced the challenges as we worked on the GUI since it was a bigger task than we had envisioned because there were more technical tasks such as asking the user if they would like to see everything that had been sorted or just a specific number. The team had to put extra time on reading the csv files since the reading we had originally done was causing some issues. Additionally, when we were working with our sorts, we noticed that it was taking in floats incorrectly so the sorting was inaccurate which took us some time to figure out. One of the biggest challenges we faced was that when we stored the information in the VideoGame class, we kept getting a memory error because some of the entries on the csv file were empty. However, we were able to solve it by adding an edge case handler.  

If you were to start once again as a group, any changes you would make to the project and/or workflow?
If we got the opportunity to restart this project, we would have planned the objective more thoroughly from the beginning since that is what caused our group the biggest setbacks. This would have given us more time to focus on the GUI and have clearer expectations on what we wanted to accomplish in our platform. We would have also taken more time to understand how we wanted to sort the data since we had to change from arrays to vectors and the integers to floats. Other than those minor changes, we think this project was essential to our learning.

Comment on what each of the members learned through this process. 
Paola: Throughout this project, I learned the value of collaboration in coding. While I’ve had some negative group experiences in the past, this project highlighted how working together can exponentially improve the outcome. After coding the sorting methods, I also have a better understanding of how sorting works and the algorithms that need to be applied and saw how big the time complexity variants affect how fast a program runs. Additionally, I got more experience with using GitHub as it is a platform I do not usually use. After this project, I am confident that not only am I a better programmer but also a better teammate. 

Camila: Throughout the completion of this project, I was able to learn a variety of things. For one, I got much more accommodated with GitHub, a platform that I know will be essential in the working environment in the future. I was also able to learn collaboration skills when it comes to coding. My group and I were able to split tasks depending on our strong suits and work accordingly in an effective manner. I also learned a lot about file reading and finding useful datasets for a project, something that I had not done in years and needed a bit of a recap on.

Omar: Working on this project taught me a lot about the complexity of building a complex system. For instance, while developing the GUI, I gained a deep appreciation for the effort required to design a user-friendly interface that processes and responds effectively to user inputs. I also improved my understanding of GitHub, which has given me the confidence to use it in my personal projects. Additionally, I worked on creating a class for the video game CSV file, which allowed me to explore the functionality of custom classes beyond the basic use of strings and integers in a vector.


References:

Kapoor, A. (2024, August 9). Sorting [PowerPoint slides]
std::clock - cppreference.com
Video-Game-Sales-Dataset/Video_Games.csv at main · Bakikhan/Video-Game-Sales-Dataset
parsing - How can I read and parse CSV files in C++? - Stack Overflow
cin in C++ - GeeksforGeeks
